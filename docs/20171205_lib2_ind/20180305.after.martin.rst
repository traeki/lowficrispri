================================
META GOAL 1: Design Next Library
================================

* Identify most phenotypically informative guides in existing set
* Predict efficacy/information of future guides.

===============================================================
META GOAL 2: Extract Biological Insight From Growth Experiments
===============================================================

* Distinguish **Biology** vs. **Noise** vs. **Bias**
* Ascribe semantics to mathematical **Biology**

=========
Questions
=========

1. How can we best estimate growth phenotypes?

  * What is "true gamma"? (gamma is not a fixed point, varies by context.)
  * Is SVD-smoothing data a good approximation?
  * How can we validate/evaluate our approximation?
  * How many components should we retain?

2. How can we best characterize/clean **Noise** and **Bias**?

  * Are noise/bias features reliably *sequestered* by SVD?
  * Are noise/bias features reliably *separated* by SVD?
  * Is PCA on transpose matrix a good path to predicting bias?

3. Can we use SVD to separate unknown effects from known effects?

  * In-condition vs. cross-condition (i.e. beak prevention)
  * Sequence effects vs. gene effects (i.e. guide design)

==========
Take aways
==========

1. **Do heatmaps**

  * of gammas
  * of raw log counts
  * normalize by initial count
  * cluster (if only to make rendering plausible)

2. Martin totally digs the transpose-SVD scanning

  * Identify

    * families of selected guides
    * guides that have whatever putative properties (stretches above threshold
      for homopolymer, etc.)

  * **Map those guides onto the visualization**
  * Color those guides based on a non-binary identification (similarity, in
    family vs. in-gene, etc)
  * Where do the other guies fall?
  * If they don't look like they should be included in the same set...
    * ... **Use them as Positive/Negative labels and build discriminators (SVM, ...)**
  * Can we find cases where {rule} is disrupted and then {profit}?

3. Can I collapse out...

  * ... known conditions to get at unexpected dimensions of variation
  * Martin cautions that a lot of the "unexpected dimensions" here will simply
    be a consequence of the complicated nature of *doing CRISPRi* technically.
    That might still be interesting, but it's not driving towards guide
    selection or "real" biology, for the most part.
  * ... inter-gene variability to get at guide-selection-driven variation
  * ... inter-family dimensions to get at sequence/mismatch-derived variation
  * Question left open / defferred, but *I* still think it's something to poke at.
  * Martin strongly feels that **we should be doing something to normalize
    for per-gene effects.**
  * [To me still] unclear exactly how best to do that "normalization"

4. Write a simple algorithm to, given a single gamma ascription, select 2 guides/gene

  * Compare that between methods of gamma ascription
  * Compare general guide ordering
  * Non-parametric, or whatever
  * **Evaluate the corner cases.**
  * Two methods to start:

    1. Go as late as statistically confident (how?)
    2. Use PC1
    3. (Secondary) Use PC1..N

5. Do machine learning to predict guide efficacy...

  * [Not from meeting] Add features (e.g. Nth base...) and re-compute SVD to
    see if we can find most impactful features
  * Other decomposers/discriminators/predictors...

6. Compute SVD in either orientation for just actual replicates (e.g. 5
   early-phase no-drug gammas).  How early do we see interesting variation captured.

==========
Next goals
==========

* Try SVD-painting in sets with unified span/condition.

* Expand painted set by

  * family
  * gene
  * homopolymer threshold

* Heat Maps

==========
Soon goals
==========

Design Library
--------------
* Write simple algorithm for picking guides from gammas
* Create gamma lists for

  * PC1
  * PC1..4
  * Raw average

* Non-parametric or similar comparison of ranking difference
* Or maybe just stability of selected pairs?

Build Predictor
---------------
* Add features to frame
* Try SVD "feature selection*
* Figure out basic steps to add whatever kind of predictor/classifier.

  * Remember to test-validate/bootstrap/...

============
New Analysis
============

SVD fits on only same-condition/same-span data lose fidelity because there
aren't enough counter-example dimensions to distinguish random-walk false
positives from the actual N-dimensional bias in the beak.

Since we already know something about the subspaces in which we are and are not
looking for signals, we want to bifurcate a space of measurements into
"considered" and "ignored" subspaces, and then compute SVD over those spaces to
find "interesting" signals and "noise/bias" signals, maybe?

What would that look like?

If we have a space Y of expected interaction dimensions, the range of those
dimensions G = R(Y) is the interesting signals, and the null set B = N(Y) is
the stuff we want to ignore, and/or the problematic biases.

QUESTION: What would it mean for something to have components in both spaces?

ANSWER?: Unclear, but such a thing would by definition have a shadow in each
space, so we should find out.  I think it's mandatory that no vector (or
component thereof) can exist outside G and B at the same time.

If I define an m x m matrix M where M(i,j) is 1 if I care about the
relationship between measurement i and measurement j, and zero otherwise, I
think that matrix is the "Y" above, provided the relationships I do and do not
care about can be specified pairwise.

What would it mean for this to break down?  I certainly don't have a
relationship I care about that includes part of a measurement, that's got to be
all or nothing.  So this would mean I have a relationship that involves more
than two whole axes, but is not described by pairwise relationships.  That's
nonsense, clearly.  So, okay, we're good there.  the issue is really that I
could in theory fuck up and not fully specify a subspace.  If I have M[a, b] ==
0 and M[b, c] == 0, I'm pretty sure that means I better have M[a,c] == 0.
Otherwise I could have, like, no relationship between span a and span b, no
relationship betwen span b and span c, but somehow a relationship between span
a and span c.  Or a relationship between a and b, but not b and a, also bad.

But as long as I get that right, I think that matrix should flatten out the
"don't care"dimensions.  Now, is there a way to flatten everything *else*?

Also, that might all be kind of nonsense.  Not sure what M*x really would do,
here...  Is M really dropping out exactly the stuff in the null space of Y?

I might need to **Standardize** my input matrix.  Would this help with current
PCA efforts?
